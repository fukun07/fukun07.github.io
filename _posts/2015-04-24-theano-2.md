---
layout: post

title: 简明Theano教程（2）：基础知识

date: 2015-04-24 20:20:53

categories: Theano
---

这一节我们将接触到theano的一些基本知识，包括：

- 使用符号变量
- 编译theano函数
- 使用shared变量
- 使用updates参数
- 自动求梯度

本节所有代码块都可以独立运行，建议安装[pycharm](https://www.jetbrains.com/pycharm/)来运行查看。当然也可以利用ipython或者[ipython notebook](http://ipython.org/install.html)。ipython notebook使用体验很好，但是在开发实际程序时我还是更喜欢pycharm。如果需安装ipython请用：

	sudo pip install ipython

## 使用符号变量

我们先来看一个例子：

	import theano
	import theano.tensor as T
	
	a = T.scalar('a')
	b = T.scalar('b')
	y = 2 * a + b ** 3
	theano.pp(y)

Theano的符号变量是其精髓，它们都定义在theano.tensor这个模块中，因此在第2行我们先import这个模块，并重命名为T。Tensor在数学上是张量的意思，就是矩阵的高维扩展，因此矩阵可以理解成2维的tensor。

接着我们定义了两个符号变量，分别叫做a和b，他们的类型都被指定为标量scalar。在初始化变量时，我们传入了一个字符串作为变量的名字。注意，这个名字只是一个别名，不要求跟变量名一致。

Theano的设计原则之一就是尽量与python及NumPy保持语法一致。因此我们可以直接运用python的语法定义y，y在数学上的表达式为y = 2a + b^3。我们可以调用theano内置的打印函数theano.pp()来查看y的表达式，运行结果如下：

	((TensorConstant{2} * a) + (b ** TensorConstant{3}))
	
TensorConstant是theano.tensor中的常数类型。除了它和上面使用的scalar外，常用的变量类型还有（完全列表请移步[官网链接](http://deeplearning.net/software/theano/library/tensor/basic.html)）：

- theano.tensor.vector （向量）
- theano.tensor.matrix （矩阵）
- theano.tensor.tensor3 （3维tensor）
- theano.tensor.tensor4 （4维tensor）

注意，符号变量只是定义了数据类型和计算表达式，并没有赋予任何数值。

## 编译theano函数

我们可以用符号变量定义出各种表达式，那么如何利用这些符号变量的表达式来做计算呢？theano提供了一个叫function的函数，用于将符号变量表达式编译为计算函数。在上一节的例子上做扩充：

	import theano
	import theano.tensor as T

	a = T.scalar('a')
	b = T.scalar('b')
	y = 2 * a + b ** 3

	func = theano.function(inputs=[a, b], outputs=y)

	print func(1, 2)
	print func(2, 1)

注意调用theano.function的那一句，它生成了一个函数句柄，这个句柄被赋值给了func。在之后就可以像普通函数一样调用func来做计算。在这个例子中，我们用到了theano.function的两个参数：

- 输入inputs：必须是一个list，意味着即便只有一个输入，传入的时候要加上中括号变成list。
- 输出outputs：可以是单个变量，也可以是list。

上述代码的运行结果是：

	10.0
	5.0

不妨简单验算一下，将a=1, b=2代入数学表达式可得y=10。在theano中，我们只需定义好符号变量之间的计算关系，然后调用theano.function()，指定输入和输出对应哪些变量即可获得计算函数。而且，theano会先生成对应的C代码再进行编译，使生成的计算函数效率与C语言一致。

theano.function在编译时也会对表达式做一定的优化。例如，它会将y = x * x / x 自动简化为 y = x。当模型结构比较复杂时，这样的优化会使得theano.function运行很慢，编译一个函数通常会有好几分钟。

## 使用shared变量
前面已经提到，符号变量是不存储任何数值的，只有经过theano.function的编译后才能计算具体数值。但是，在很多场合下我们需要一种能够存储数值的变量。比如Logistic Regression里的权重向量，我们不希望每次计算时还得单独传递一个参数。好在theano提供了一种解决方案：使用shared变量。我们还是先来看一个例子：

	import theano
	import theano.tensor as T

	w = theano.shared(2.0)
	b = theano.shared(1.0)

	x = T.scalar('x')
	y = w * x + b

	func = theano.function(inputs=[x], outputs=y)

	print func(3)
	print w.get_value()

	w.set_value(4.0)

	print func(3)
	print w.get_value()
	
输出结果是:

	7.0
	2.0
	13.0
	4.0
	
我们依次来说明这段代码。首先我们定义了两个shared变量w和b，这两个变量是带数值的，分别是2.0和1.0。在定义计算表达式时，shared变量的用法和符号变量一样，因此两种变量可以混着写在表达式里。但是，因此w和b本身是带数值的，所以在编译theano.function时并不需要在输入列表里给w和b留出位置，函数会使用2.0和1.0来计算。所以第一个输出结果是7.0。

注意，shared变量本身并不是一个数，赋值需要通过本身的set_value()方法，获取值则需要通过get_value()方法。第二个输出结果是2.0，因此此时w的值还是初始值没有改变。

之后，我们将w的值重新设定为4.0，此时在func(3)的计算会使用新的w值，计算结果为13.0。然后打印w值发现已经是4.0了。重新设定shared值之后，并不需要用theano.function重新编译。

## 使用updates参数

theano.function在编译计算函数时，可以使用updates参数来指定shared变量的修改规则。还是先看一个例子：

	import theano
	import theano.tensor as T

	x = T.scalar('x')
	w = theano.shared(2.0)
	b = theano.shared(1.0)
	updates = [(w, w+10), (b, b+10)]
	func = theano.function([x], w*x+b, updates=updates)

	print 'w=%.1f, b=%.1f' % (w.get_value(), b.get_value())
	y = func(1)
	print 'w=%.1f, b=%.1f, y=%.1f' % (w.get_value(), b.get_value(), y)
	y = func(1)
	print 'w=%.1f, b=%.1f, y=%.1f' % (w.get_value(), b.get_value(), y)

输出结果为：

	w=2.0, b=1.0
	w=12.0, b=11.0, y=3.0
	w=22.0, b=21.0, y=23.0

在这段代码中，我们定义了两个shared变量，w和b，初始值分别是2.0和1.0。然后，我们定义了一组更新规则，这个规则是一个list，其中每个元素是一个二元tuple，每个tuple由更新前、更新后对应构成。可参加下面的格式：
	
	[(shared变量1, 计算表达式1), (shared变量2, 计算表达式2), ...]

当然，更新规则在theano里也可以基于字典来表示。格式为：

	{shared变量1: 计算表达式1, shared变量2: 计算表达式2}

在旧版本theano中这两种方法是等价的。但在最新版本中，theano推荐使用有序的形式，也即第一种方法，因此字典是不保证关键字顺序的。

回到代码，定义完updates后，我们将其传递给theano.function()，并指定参数“updates=”。它的功能就是每调用一次即按照updates规则修改一次。从输出结果来看，调用func(1)时，函数先用旧的w和b值计算出2.0*1+1.0=3，然后才对w和b做更新。这个特性很方便，比如我们在训练一个Logistic Regression模型时，函数会先用旧的参数值计算目标函数，然后才会对参数做更新。

## 自动计算梯度

我们可以用符号变量定义输入输出，可以用shared变量存储模型参数，可以用updates指定参数更新规则。现在，距离一个完整的基于梯度方法的训练框架还差一步：获取参数梯度。

Theano最为突出的优势就是自动求梯度，具体的原理放在以后讲，这里只介绍其使用方法。先看一段代码：

	import theano
	import theano.tensor as T

	a = T.scalar('a')
	b = T.scalar('b')

	y = 2 * a + b ** 3

	g = T.grad(y, [a, b])

	func = theano.function([a, b], g)

	ga, gb = func(3, 2)
	print 'gradient of a = %.1f' % ga
	print 'gradient of b = %.1f' % gb

输出结果为：

	gradient of a = 2.0
	gradient of b = 12.0

使用T.grad()可以方便得求出梯度。第一个参数为cost，必须为scalar；第二个参数为自变量。返回值是由符号变量定义的梯度表达式，其结构与自变量一致。例如，自变量是[a, b]，则求出的梯度g是一个包含两个元素的list，分别对应a和b的梯度。如果自变量只有一个，可以不写成list的形式，此时梯度
g也不是一个list。

至此，我们已经拥有了足够建立一个机器学习模型的工具，在下一章，我们将构建一个实际的Logistic Regression模型。
